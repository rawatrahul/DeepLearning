{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vggnet_in_keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "H9ewOfPMdrzT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Vgg in keras"
      ]
    },
    {
      "metadata": {
        "id": "rwXRA5s-dz8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using keras to create an alexnet copy"
      ]
    },
    {
      "metadata": {
        "id": "LYBkgQaOefom",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Set seed for reproducibility"
      ]
    },
    {
      "metadata": {
        "id": "0quZ5O3YcA_M",
        "colab_type": "code",
        "outputId": "b1583f0b-4d98-4431-bcd9-9b2ab130ef8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "!pip install tflearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\r\u001b[K    10% |███▎                            | 10kB 22.9MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 20kB 860kB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 30kB 1.3MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 40kB 851kB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 51kB 1.1MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 61kB 1.3MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 71kB 1.5MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▋     | 81kB 1.7MB/s eta 0:00:01\r\u001b[K    93% |██████████████████████████████  | 92kB 1.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 102kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1pGirKVHexHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Load dependencies"
      ]
    },
    {
      "metadata": {
        "id": "MPP4y-FycWxe",
        "colab_type": "code",
        "outputId": "1be87b83-c257-4e30-c060-24eadb46fc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tflearn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fBOsxiWzfLSc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Load and preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "HhAoG5kUca1W",
        "colab_type": "code",
        "outputId": "417fd8f5-fac0-48ce-98da-643a5878be7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "import tflearn.datasets.oxflower17 as oxflower17\n",
        "X, Y = oxflower17.load_data(one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Succesfully downloaded', '17flowers.tgz', 60270631, 'bytes.')\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QesZCWpGfUqK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Design neural network architecture"
      ]
    },
    {
      "metadata": {
        "id": "7J4LwWpVcgaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, 3, activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(Conv2D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, 3, activation='relu'))\n",
        "model.add(Conv2D(128, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, 3, activation='relu'))\n",
        "model.add(Conv2D(256, 3, activation='relu'))\n",
        "model.add(Conv2D(256, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, 3, activation='relu'))\n",
        "model.add(Conv2D(512, 3, activation='relu'))\n",
        "model.add(Conv2D(512, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, 3, activation='relu'))\n",
        "model.add(Conv2D(512, 3, activation='relu'))\n",
        "model.add(Conv2D(512, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(17, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cfp4V8g2dMP2",
        "colab_type": "code",
        "outputId": "81b8b4bb-353b-4bea-e9cb-6b1f246951de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 220, 220, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 110, 110, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 108, 108, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 106, 106, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 53, 53, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 53, 53, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 51, 51, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 49, 49, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 47, 47, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 21, 21, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 19, 19, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 17, 17, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 17)                69649     \n",
            "=================================================================\n",
            "Total params: 33,672,785\n",
            "Trainable params: 33,669,841\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "skJBpEiXfeB3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Configure model"
      ]
    },
    {
      "metadata": {
        "id": "9YNRcSuFdPoR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5l04BNuzff_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Train!"
      ]
    },
    {
      "metadata": {
        "id": "7n59K-YSdUHj",
        "colab_type": "code",
        "outputId": "efaadb7b-d89b-4dda-d5b0-904ef0b22212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3471
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1224 samples, validate on 136 samples\n",
            "Epoch 1/100\n",
            "1224/1224 [==============================] - 50s 41ms/step - loss: 3.2934 - acc: 0.1315 - val_loss: 14.9310 - val_acc: 0.0735\n",
            "Epoch 2/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 2.9239 - acc: 0.1830 - val_loss: 11.4183 - val_acc: 0.0956\n",
            "Epoch 3/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 2.3374 - acc: 0.2508 - val_loss: 10.7930 - val_acc: 0.1397\n",
            "Epoch 4/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 2.1947 - acc: 0.2606 - val_loss: 3.1927 - val_acc: 0.2279\n",
            "Epoch 5/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.9608 - acc: 0.3219 - val_loss: 2.6281 - val_acc: 0.2206\n",
            "Epoch 6/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.8544 - acc: 0.3570 - val_loss: 2.9298 - val_acc: 0.2059\n",
            "Epoch 7/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.9063 - acc: 0.3456 - val_loss: 4.6632 - val_acc: 0.2426\n",
            "Epoch 8/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.7963 - acc: 0.3856 - val_loss: 6.2292 - val_acc: 0.1912\n",
            "Epoch 9/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.7062 - acc: 0.4003 - val_loss: 3.8326 - val_acc: 0.2279\n",
            "Epoch 10/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.5610 - acc: 0.4387 - val_loss: 2.1993 - val_acc: 0.3088\n",
            "Epoch 11/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.5945 - acc: 0.4379 - val_loss: 3.5129 - val_acc: 0.2426\n",
            "Epoch 12/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.5604 - acc: 0.4444 - val_loss: 3.3628 - val_acc: 0.2794\n",
            "Epoch 13/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.6069 - acc: 0.4338 - val_loss: 2.3470 - val_acc: 0.3529\n",
            "Epoch 14/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.4670 - acc: 0.4747 - val_loss: 3.9143 - val_acc: 0.2868\n",
            "Epoch 15/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.5605 - acc: 0.4387 - val_loss: 3.1291 - val_acc: 0.3309\n",
            "Epoch 16/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.4772 - acc: 0.4796 - val_loss: 4.2729 - val_acc: 0.2353\n",
            "Epoch 17/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.5216 - acc: 0.4583 - val_loss: 3.7948 - val_acc: 0.2059\n",
            "Epoch 18/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.6112 - acc: 0.4420 - val_loss: 5.0077 - val_acc: 0.2426\n",
            "Epoch 19/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.6203 - acc: 0.4363 - val_loss: 5.4974 - val_acc: 0.2279\n",
            "Epoch 20/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.5569 - acc: 0.4575 - val_loss: 3.8776 - val_acc: 0.2206\n",
            "Epoch 21/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.4636 - acc: 0.4681 - val_loss: 3.2133 - val_acc: 0.3750\n",
            "Epoch 22/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.4464 - acc: 0.4853 - val_loss: 2.5764 - val_acc: 0.3162\n",
            "Epoch 23/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3452 - acc: 0.5163 - val_loss: 2.6809 - val_acc: 0.4191\n",
            "Epoch 24/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3636 - acc: 0.5065 - val_loss: 2.5694 - val_acc: 0.4044\n",
            "Epoch 25/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2281 - acc: 0.5743 - val_loss: 2.8320 - val_acc: 0.3456\n",
            "Epoch 26/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3174 - acc: 0.5400 - val_loss: 2.1082 - val_acc: 0.4191\n",
            "Epoch 27/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2697 - acc: 0.5482 - val_loss: 8.6105 - val_acc: 0.1912\n",
            "Epoch 28/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3111 - acc: 0.5449 - val_loss: 7.1248 - val_acc: 0.2279\n",
            "Epoch 29/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.1592 - acc: 0.5940 - val_loss: 2.7129 - val_acc: 0.3897\n",
            "Epoch 30/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3201 - acc: 0.5384 - val_loss: 3.2941 - val_acc: 0.3897\n",
            "Epoch 31/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2617 - acc: 0.5727 - val_loss: 6.9932 - val_acc: 0.1838\n",
            "Epoch 32/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.8085 - acc: 0.3938 - val_loss: 8.3425 - val_acc: 0.1471\n",
            "Epoch 33/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.4674 - acc: 0.4624 - val_loss: 5.9420 - val_acc: 0.2206\n",
            "Epoch 34/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.4024 - acc: 0.4959 - val_loss: 2.7432 - val_acc: 0.3088\n",
            "Epoch 35/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3952 - acc: 0.4918 - val_loss: 2.9758 - val_acc: 0.3015\n",
            "Epoch 36/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2918 - acc: 0.5400 - val_loss: 1.8969 - val_acc: 0.3897\n",
            "Epoch 37/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2910 - acc: 0.5605 - val_loss: 1.9213 - val_acc: 0.5294\n",
            "Epoch 38/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2839 - acc: 0.5449 - val_loss: 2.8943 - val_acc: 0.3456\n",
            "Epoch 39/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2747 - acc: 0.5621 - val_loss: 2.0583 - val_acc: 0.3897\n",
            "Epoch 40/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.3094 - acc: 0.5449 - val_loss: 1.9947 - val_acc: 0.5000\n",
            "Epoch 41/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.0813 - acc: 0.6038 - val_loss: 2.2564 - val_acc: 0.4412\n",
            "Epoch 42/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.1318 - acc: 0.6087 - val_loss: 1.8950 - val_acc: 0.4853\n",
            "Epoch 43/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2245 - acc: 0.5752 - val_loss: 2.7772 - val_acc: 0.3603\n",
            "Epoch 44/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.0523 - acc: 0.6275 - val_loss: 2.4102 - val_acc: 0.4779\n",
            "Epoch 45/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.6493 - acc: 0.4624 - val_loss: 5.7033 - val_acc: 0.1691\n",
            "Epoch 46/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3447 - acc: 0.5114 - val_loss: 5.7615 - val_acc: 0.1324\n",
            "Epoch 47/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.2428 - acc: 0.5531 - val_loss: 3.1146 - val_acc: 0.2353\n",
            "Epoch 48/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.2240 - acc: 0.5719 - val_loss: 3.6899 - val_acc: 0.2868\n",
            "Epoch 49/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.2986 - acc: 0.5433 - val_loss: 1.8753 - val_acc: 0.4926\n",
            "Epoch 50/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.1170 - acc: 0.6038 - val_loss: 2.1859 - val_acc: 0.3750\n",
            "Epoch 51/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.1203 - acc: 0.6078 - val_loss: 2.7223 - val_acc: 0.3971\n",
            "Epoch 52/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.0551 - acc: 0.6078 - val_loss: 1.8732 - val_acc: 0.5147\n",
            "Epoch 53/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.0607 - acc: 0.6209 - val_loss: 2.3757 - val_acc: 0.4412\n",
            "Epoch 54/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 1.1691 - acc: 0.5858 - val_loss: 1.6854 - val_acc: 0.4853\n",
            "Epoch 55/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.1132 - acc: 0.6046 - val_loss: 2.0929 - val_acc: 0.5074\n",
            "Epoch 56/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 0.9289 - acc: 0.6609 - val_loss: 1.9220 - val_acc: 0.4779\n",
            "Epoch 57/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.0820 - acc: 0.6266 - val_loss: 2.0712 - val_acc: 0.4559\n",
            "Epoch 58/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.9663 - acc: 0.6536 - val_loss: 1.6376 - val_acc: 0.5294\n",
            "Epoch 59/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.8274 - acc: 0.7108 - val_loss: 1.5692 - val_acc: 0.5662\n",
            "Epoch 60/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.8405 - acc: 0.6944 - val_loss: 2.6529 - val_acc: 0.4118\n",
            "Epoch 61/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.8882 - acc: 0.6863 - val_loss: 1.8195 - val_acc: 0.5735\n",
            "Epoch 62/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.9179 - acc: 0.6822 - val_loss: 1.5480 - val_acc: 0.5441\n",
            "Epoch 63/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 0.7694 - acc: 0.7239 - val_loss: 5.2260 - val_acc: 0.1397\n",
            "Epoch 64/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 0.7917 - acc: 0.7222 - val_loss: 1.8364 - val_acc: 0.5147\n",
            "Epoch 65/100\n",
            "1224/1224 [==============================] - 30s 24ms/step - loss: 0.9721 - acc: 0.6667 - val_loss: 1.6825 - val_acc: 0.4706\n",
            "Epoch 66/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.8321 - acc: 0.7042 - val_loss: 1.6147 - val_acc: 0.5735\n",
            "Epoch 67/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.8250 - acc: 0.7230 - val_loss: 2.2384 - val_acc: 0.4632\n",
            "Epoch 68/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.8212 - acc: 0.7051 - val_loss: 1.9427 - val_acc: 0.5294\n",
            "Epoch 69/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.7520 - acc: 0.7516 - val_loss: 1.5179 - val_acc: 0.6176\n",
            "Epoch 70/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.7408 - acc: 0.7304 - val_loss: 1.8771 - val_acc: 0.5662\n",
            "Epoch 71/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.7273 - acc: 0.7459 - val_loss: 1.2957 - val_acc: 0.6250\n",
            "Epoch 72/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.6321 - acc: 0.7729 - val_loss: 2.0949 - val_acc: 0.5809\n",
            "Epoch 73/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.6518 - acc: 0.7827 - val_loss: 2.1806 - val_acc: 0.5294\n",
            "Epoch 74/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 0.7597 - acc: 0.7500 - val_loss: 6.9772 - val_acc: 0.1838\n",
            "Epoch 75/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 3.1009 - acc: 0.1569 - val_loss: 13.9390 - val_acc: 0.0735\n",
            "Epoch 76/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 2.0317 - acc: 0.2802 - val_loss: 13.1256 - val_acc: 0.0956\n",
            "Epoch 77/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.8638 - acc: 0.3350 - val_loss: 8.0596 - val_acc: 0.0882\n",
            "Epoch 78/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.8440 - acc: 0.3440 - val_loss: 6.1196 - val_acc: 0.1103\n",
            "Epoch 79/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.8024 - acc: 0.3611 - val_loss: 4.1886 - val_acc: 0.1176\n",
            "Epoch 80/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.8003 - acc: 0.3374 - val_loss: 3.8829 - val_acc: 0.0809\n",
            "Epoch 81/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.6585 - acc: 0.3832 - val_loss: 3.0240 - val_acc: 0.0956\n",
            "Epoch 82/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.6055 - acc: 0.3938 - val_loss: 2.1510 - val_acc: 0.2279\n",
            "Epoch 83/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.5682 - acc: 0.4322 - val_loss: 2.5602 - val_acc: 0.2721\n",
            "Epoch 84/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.4943 - acc: 0.4436 - val_loss: 2.4186 - val_acc: 0.3088\n",
            "Epoch 85/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.4157 - acc: 0.4804 - val_loss: 2.6096 - val_acc: 0.3162\n",
            "Epoch 86/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3962 - acc: 0.5074 - val_loss: 2.3733 - val_acc: 0.2647\n",
            "Epoch 87/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3794 - acc: 0.5065 - val_loss: 4.2792 - val_acc: 0.1985\n",
            "Epoch 88/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3670 - acc: 0.5025 - val_loss: 2.6766 - val_acc: 0.3015\n",
            "Epoch 89/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3700 - acc: 0.5147 - val_loss: 2.7416 - val_acc: 0.3897\n",
            "Epoch 90/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.4490 - acc: 0.4730 - val_loss: 2.2073 - val_acc: 0.4265\n",
            "Epoch 91/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3252 - acc: 0.5261 - val_loss: 1.8280 - val_acc: 0.4338\n",
            "Epoch 92/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.3174 - acc: 0.5008 - val_loss: 2.0556 - val_acc: 0.3603\n",
            "Epoch 93/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.2616 - acc: 0.5392 - val_loss: 2.2488 - val_acc: 0.3750\n",
            "Epoch 94/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.2564 - acc: 0.5466 - val_loss: 2.1544 - val_acc: 0.3750\n",
            "Epoch 95/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.2038 - acc: 0.5858 - val_loss: 1.9375 - val_acc: 0.4265\n",
            "Epoch 96/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.2193 - acc: 0.5621 - val_loss: 2.0613 - val_acc: 0.3603\n",
            "Epoch 97/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.0876 - acc: 0.6176 - val_loss: 1.8681 - val_acc: 0.4265\n",
            "Epoch 98/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.1306 - acc: 0.5866 - val_loss: 1.6164 - val_acc: 0.4632\n",
            "Epoch 99/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.1175 - acc: 0.6144 - val_loss: 1.5423 - val_acc: 0.4853\n",
            "Epoch 100/100\n",
            "1224/1224 [==============================] - 29s 24ms/step - loss: 1.0744 - acc: 0.6046 - val_loss: 1.6027 - val_acc: 0.5221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff02c9dcf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "dkxdxUP3dWcJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}